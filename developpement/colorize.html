<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Practical session 2 - AI Frameworks</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/docco.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../index.html">AI Frameworks</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../index.html" class="nav-link">Home</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Courses <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Development tools for Data Scientist</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="pytorch.html" class="dropdown-item">Introduction to Pytorch</a>
</li>
            
<li>
    <a href="git_intro.html" class="dropdown-item">Introduction to Git</a>
</li>
            
<li>
    <a href="docker.html" class="dropdown-item">Introduction to Docker</a>
</li>
            
<li>
    <a href="api.html" class="dropdown-item">Introduction to REST APIs</a>
</li>
            
<li>
    <a href="mnist.html" class="dropdown-item">Practical session 1</a>
</li>
            
<li>
    <a href="colorize.html" class="dropdown-item active">Practical session 2</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Recommender systems</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../rec_sys/rec_sys.html" class="dropdown-item">Course and practical session</a>
</li>
            
<li>
    <a href="../rec_sys/quizz.html" class="dropdown-item">Quizz</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="../schedule.html" class="nav-link">Schedule</a>
                            </li>
                            <li class="navitem">
                                <a href="https://github.com/DavidBert/AIF2024" class="nav-link">Github repository</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="mnist.html" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../rec_sys/rec_sys.html" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#development-for-data-scientist" class="nav-link">Development for Data Scientist:</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#practical-session-2-deploying-a-digit-classifier" class="nav-link">Practical session 2: Deploying a digit classifier</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#practical-session-repository" class="nav-link">Practical session repository:</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data" class="nav-link">Data</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#the-network-architecture" class="nav-link">The network architecture</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#training-script" class="nav-link">Training script</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#api-web-app-and-deployment" class="nav-link">API, Web app and deployment</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#solutions" class="nav-link">Solutions:</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="development-for-data-scientist">Development for Data Scientist:</h1>
<h2 id="practical-session-2-deploying-a-digit-classifier">Practical session 2: Deploying a digit classifier</h2>
<p>Now that you have a good understanding of the PyTorch framework and how to deploy your model through a REST API or a web application, you will develop an application that will colorize black and white images.</p>
<p>Once again, you are expected to use Python scripts to train your model and to deploy it.</p>
<h2 id="practical-session-repository">Practical session repository:</h2>
<p>If you haven't already done so, create an account on <a href="https://github.com/">Github</a>.
Then fork <a href="https://github.com/DavidBert/AIF2024/tree/main">this repository</a> and clone it on your computer.<br />
<img alt="" src="../img/code/fork.png" />  </p>
<p>Then navigate to the <code>developpement/colorize</code> folder.<br />
Your working directory should look like this:</p>
<pre><code class="language-bash">code/
├── data_utils.py
├── model.py
├── train.py
├── colorize_api.py
├── colorize_webapp.py
├── test_api.ipynb
sample_images/
├── img1.jpg
├── img2.jpg
├── img3.jpg
├── img4.jpg
├── img5.jpg
requirements.txt

download_landscapes.sh
</code></pre>
<!-- The solution is available here.  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DavidBert/N7-techno-IA/blob/master/code/developpement/colorize_solution.ipynb)  
Try to complete the practical session without looking at it! -->

<h2 id="data">Data</h2>
<p>We will be working with the <a href="https://github.com/ml5js/ml5-data-and-models/tree/master/datasets/images/landscapes">Landscapes dataset</a> composed of 4000 images in seven categories of landscapes (city, road, mountain, lake, ocean, field, and forest).
Instead of using it to train a classifier, we will use it to train a neural network to colorize black and white images.<br />
<img alt="" src="../img/gcloud_b%26w.png" /> <img alt="" src="../img/gcloud_color.png" /><br />
Run the <code>download_landscapes.sh</code> script to download and extract the dataset.</p>
<pre><code class="language-bash">./download_landscapes.sh
</code></pre>
<p>Here, we only have access to color images, so we will have to generate our own black and white images.
The file <code>data_utils.py</code> contains some useful functions to load the dataset.<br />
In particuler given a dataset containing landscape images, the function <code>get_colorized_dataset_loader</code> returns a PyTorch <code>DataLoader</code> object that can be used to iterate over the dataset yielding batches of black and white images and their corresponding colorized version.  </p>
<h2 id="the-network-architecture">The network architecture</h2>
<p>We will use a particular category of neural networks to perform the colorization operation: <a href="https://arxiv.org/abs/1505.04597">Unets</a>.<br />
Initially designed for Biomedical Image Segmentation, Unets offer state-of-the-art performances in many segmentation tasks.<br />
Unets are a particular form of Auto-Encoders using skip connections between corresponding layers of the encoder and the decoder.
<img alt="" src="../img/AU_UNet.png" />  </p>
<p>The network architecture is defined in the <code>unet.py</code> file and need to be completed.  <br />
<img alt="" src="../img/Unet.png" /></p>
<p>Help yourself with the above image to implement a Unet network using the template located in the <code>unet.py</code> file:</p>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

def double_conv(in_channels, out_channels):
    # returns a block compsed of two Convolution layers with ReLU activation function
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, 3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, 3, padding=1),
        nn.ReLU()
    )   

class DownSampleBlock(nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv_block = ...
        self.maxpool = ...

    def forward(self, x):
        x_skip = ...
        out = ... 

        return out , x_skip

class UpSampleBlock(nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv_block = ...
        self.upsample = ... # use nn.Upsample

    def forward(self, x, x_skip):
        x = self.upsample(x)
        x = torch.cat([x, x_skip], dim=1) # concatenates x and x_skip
        x = self.conv_block(x)

        return x


class UNet(nn.Module):

    def __init__(self):
        super().__init__()

        self.downsample_block_1 = ...
        self.downsample_block_2 = ...
        self.downsample_block_3 = ...
        self.middle_conv_block = double_conv(128, 256)        


        self.upsample_block_3 = ...
        self.upsample_block_2 = ...
        self.upsample_block_1 = ...

        self.last_conv = nn.Conv2d(32, 3, 1)


    def forward(self, x):
        x, x_skip1 = ...
        x, x_skip2 = ...
        x, x_skip3 = ... 

        x = self.middle_conv_block(x)

        x = #use upsampleblock_3 and x_skip3
        x = #use upsampleblock_2 and x_skip2
        x = #use upsampleblock_1 and x_skip1       

        out = F.sigmoid(self.last_conv(x))

        return out


if __name__=='__main__':
    x = torch.rand(16,1,224,224)
    net = UNet()
    y = net(x)
    assert y.shape == (16,3,224,224)
    print('Shapes OK')

</code></pre>
<p>Check that your network is producing correct outputs by running your file with:</p>
<pre><code>python model.py
</code></pre>
<h2 id="training-script">Training script</h2>
<p>You will now implement the training procedure.  </p>
<p>Training a network to colorize images is a supervised regression problem.<br />
Consider <span class="arithmatex">\(x\)</span> a grayscaled image and <span class="arithmatex">\(y\)</span> its corresponding colored image.
Training a parametrized network <span class="arithmatex">\(f_\theta\)</span> to predict colorized images <span class="arithmatex">\(ŷ\)</span> amounts to minimizing the distance between the prediction <span class="arithmatex">\(ŷ\)</span> and the actual <span class="arithmatex">\(y\)</span>.<br />
That is to say minimizing <span class="arithmatex">\(MSE(y, f_\theta(x))\)</span>.</p>
<p>Fill the <code>train.py</code> file to train a UNet to colorize images (you can inspire yourself from the one in the MNIST example. However, be careful in your criterion choice):  </p>
<pre><code class="language-python">import argparse # to parse script arguments
from statistics import mean # to compute the mean of a list
from tqdm import tqdm #used to generate progress bar during training

import torch
import torch.optim as optim 
from torch.utils.tensorboard import SummaryWriter
from  torchvision.utils import make_grid #to generate image grids, will be used in tensorboard 

from data_utils import get_colorized_dataset_loader # dataloarder
from unet import UNet

# setting device on GPU if available, else CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def train(net, optimizer, loader, epochs=5, writer=None):
    criterion = ...
    for epoch in range(epochs):
        running_loss = []
        t = tqdm(loader)
        for x, y in t: # x: black and white image, y: colored image 
            ...
            ...
            ...
            ...
            ...
            ...
            ...
            ...
        if writer is not None:
            #Logging loss in tensorboard
            writer.add_scalar('training loss', mean(running_loss), epoch)
            # Logging a sample of inputs in tensorboard
            input_grid = make_grid(x[:16].detach().cpu())
            writer.add_image('Input', input_grid, epoch)
            # Logging a sample of predicted outputs in tensorboard
            colorized_grid = make_grid(outputs[:16].detach().cpu())
            writer.add_image('Predicted', colorized_grid, epoch)
            # Logging a sample of ground truth in tensorboard
            original_grid = make_grid(y[:16].detach().cpu())
            writer.add_image('Ground truth', original_grid, epoch)
    return mean(running_loss)



if __name__=='__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--exp_name', type=str, default = 'Colorize', help='experiment name')
    parser.add_argument('--data_path', ...)
    parser.add_argument('--batch_size'...)
    parser.add_argument('--epochs'...)
    parser.add_argument('--lr'...)

    exp_name = ...
    args = ...
    data_path = ...
    batch_size = ...
    epochs = ...
    lr = ...
    unet = UNet().to(device)
    loader = get_colorized_dataset_loader(path=data_path, 
                                        batch_size=batch_size, 
                                        shuffle=True, 
                                        num_workers=0)


    optimizer = optim.Adam(unet.parameters(), lr=lr)
    writer = SummaryWriter(f'runs/{exp_name}')
    train(unet, optimizer, loader, epochs=epochs, writer=writer)
    x, y = next(iter(loader))

    with torch.no_grad():
        all_embeddings = []
        all_labels = []
        for x, y in loader:
            x , y = x.to(device), y.to(device)
            embeddings = unet.get_features(x).view(-1, 128*28*28)
            all_embeddings.append(embeddings)
            all_labels.append(y)
            if len(all_embeddings)&gt;6:
                break
        embeddings = torch.cat(all_embeddings)
        labels = torch.cat(all_labels)
        writer.add_embedding(embeddings, label_img=labels, global_step=1)
        writer.add_graph(unet, x.to(device))

    # Save model weights
    torch.save(unet.state_dict(), 'unet.pth')
</code></pre>
<p>Some of you may have GPUs on their local machine.
If that is the case, you can use them to train your model.
If not, you can use Google Colab to train your model on a GPU for free.  </p>
<p>If you are using Google Colab, you are expected to do all the code development on your local machine and then send your code to collab to train your model. 
Try to run your code on your local machine for one or two minibatches to check that everything is working.
If it is the case, you can send your code to Google Colab to train your model.
To do so:
- Open the <a href="https://colab.research.google.com/github/DavidBert/AIF2024/blob/main/developpement/Colorize/run_in_colab.ipynb">run_in_colab.ipynb</a> notebook in Google Colab.
- Make sure you are connected to a GPU runtime.
- Run the first cell to download the dataset.
- Upload the files <code>data_utils.py</code>, <code>model.py</code> and <code>train.py</code> to the <code>code</code> folder in Google Colab.
- Run the second cell to launch a tensorboard instance.
- Run the third cell to launch the training.
- Download the trained model and the tensorboard logs to your local machine.</p>
<h2 id="api-web-app-and-deployment">API, Web app and deployment</h2>
<p>Complete the <code>colorize_api.py</code> file to create a Flask API that will colorize images.
The API should have a <code>/colorize</code> endpoint that will take a black and white image as input and return the colorized version of the image.
You can use the <code>test_colorize_api.py</code> file to test your API.</p>
<p>You can test your app with random balck and white images from the net. For exemple one of <a href="https://www.google.com/search?q=black+and+white+landscape&amp;client=firefox-b-d&amp;sxsrf=ALiCzsaXksCw7fTscNIIIPlJKrwyMkGK_w:1654093215988&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=2ahUKEwi-ocG0uYz4AhX7gc4BHU5HCh8Q_AUoAXoECAEQAw&amp;biw=1408&amp;bih=624&amp;dpr=1.36">these</a>.</p>
<p>You can also test your api using Postman.
To do so:
- Install <a href="https://www.postman.com/downloads/">Postman</a>.
- Launch your API.
- Open Postman.
- Create a new request.
- Set the request type to POST.
- Set the request URL to your API URL.
- Go to the Body tab.
- Select binary as the body type.
- Select a black and white image on your computer.
- Click on send.</p>
<p>Do you have any idea why the colors are so dull?</p>
<p>You can also complete the <code>colorize_web_app.py</code> file to create a web app that will colorize images.</p>
<p>Finally complete the <code>Dockerfile</code> file to deploy your app on a local server.</p>
<p>DO NOT FORGET TO DELETE YOUR DOCKER IMAGE AND CONTAINER WHEN YOU ARE DONE.</p>
<h1 id="solutions">Solutions:</h1>
<h3 id="modelpy">model.py</h3>
<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FDavidBert%2FAIF2024%2Fblob%2Fsolutions%2Fdeveloppement%2FColorize%2Fcode%2Fmodel.py&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on"></script>

<h3 id="trainpy">train.py</h3>
<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FDavidBert%2FAIF2024%2Fblob%2Fsolutions%2Fdeveloppement%2FColorize%2Fcode%2Ftrain.py&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on"></script>

<h3 id="colorize_apipy">colorize_api.py</h3>
<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FDavidBert%2FAIF2024%2Fblob%2Fsolutions%2Fdeveloppement%2FColorize%2Fcode%2Fcolorize_api.py&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on"></script>

<h3 id="colorize_web_apppy">colorize_web_app.py</h3>
<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FDavidBert%2FAIF2024%2Fblob%2Fsolutions%2Fdeveloppement%2FColorize%2Fcode%2Fcolorize_webapp.py&style=default&type=code&showBorder=on&showLineNumbers=on&showFileMeta=on&showFullPath=on&showCopy=on"></script></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../javascripts/mathjax.js" defer></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6" defer></script>
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
